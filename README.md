Wildlife Web Scraping Process

The Wildlife Web Scraping Process is a project designed to automate the collection and analysis of data from various wildlife websites.
The goal is to identify and monitor any instances of illegal animal trade happening on these websites. 

1.Wildlife Websites Link Collection Text File.
2.Python code is developed using Beautiful Soup to scrape data from the collected websites. 
This includes extracting details such as title, image, price, and URL of the products.
3.A Django web application is built to interact with the scraped data.
Users can input search terms and view details extracted from all the websites.
4.HTML files are created for the frontend view of the web application, allowing users to interact with the search functionality.
5.The frontend and backend components are integrated to create a seamless user experience for searching and viewing data.

Setup Environment: Install Python, Django, and Beautiful Soup library.
Run Web Scraping Script: Execute the Python script to scrape data from wildlife websites.
Setup Django Application: Unzip the Django web application folder and follow instructions in the README file to set up and run the application.
Access Web Application: Open a web browser and navigate to the URL where the Django application is running. Use the search functionality to query data extracted from the websites.
Review Documentation: Refer to the provided procedure guide and results visualization document for detailed insights into the project process and findings.

![image](https://github.com/HymavathiG2712/Wildlife-data-scraping/assets/122757491/7141c698-9615-4af1-bf35-cc3534c17bf0)

![image](https://github.com/HymavathiG2712/Wildlife-data-scraping/assets/122757491/f6d16229-317d-4b96-a9ed-5fb18aaba3ed)
